{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable as V\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from pytorch_lightning_lm.data_module import QuotesDataModule\n",
    "from pytorch_lightning_lm.metrics import Perplexity\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning_lm.model import RNNModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "# add PROGRAM level args\n",
    "parser.add_argument('--project-name', type=str, default='neural_lms')\n",
    "parser.add_argument('--experiment-tag', type=str, default='RNN_LM')\n",
    "parser.add_argument('--use-cuda', type=bool, default=True)\n",
    "parser.add_argument('--use-wandb', type=bool, default=True)\n",
    "parser.add_argument('--log-gradients', type=bool, default=False)\n",
    "parser.add_argument('--unk-cutoff', type=int, default=2)\n",
    "\n",
    "# add model specific args\n",
    "# parser = LitModel.add_model_specific_args(parser)\n",
    "parser.add_argument('--batch_size', type=int, default=32)\n",
    "parser.add_argument('--bptt', type=int, default=16)\n",
    "parser.add_argument('--rnn-type', type=str, default=\"LSTM\")\n",
    "parser.add_argument('--nhid', type=int, default=64)\n",
    "parser.add_argument('--nlayers', type=int, default=2)\n",
    "parser.add_argument('--pretrained-vector', type=str, default=\"fasttext.simple.300d\")\n",
    "\n",
    "# add all the available trainer options to argparse\n",
    "parser.add_argument('--max_epochs', type=int, default=25)\n",
    "parser.add_argument('--fast_dev_run', type=bool, default=True)\n",
    "# ie: now --gpus --num_nodes ... --fast_dev_run all work in the cli\n",
    "# parser = Trainer.add_argparse_args(parser)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if (torch.cuda.is_available()&args.use_cuda) else torch.device('cpu')\n",
    "experiment_name = f\"{args.experiment_tag}_{args.rnn_type}_{args.batch_size}_{args.bptt}_{args.nhid}_{args.nlayers}\"\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = experiment_name+\"_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = QuotesDataModule(\n",
    "    train_file=\"data/quotesdb/funny_quotes.train.txt\",\n",
    "    valid_file=\"data/quotesdb/funny_quotes.val.txt\",\n",
    "    test_file=\"data/quotesdb/funny_quotes.test.txt\",\n",
    "    tokenizer=None,\n",
    "    batch_size=args.batch_size,\n",
    "    bptt=args.bptt,\n",
    "    pretrained_vectors=args.pretrained_vector,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a>.<br/>\n",
       "                    Couldn't load entity due to error: Can't connect to network to query entity from API key\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error resolved after 0:00:34.660896, resuming normal operation.\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss | 0     \n",
      "1 | metric    | Perplexity       | 0     \n",
      "2 | drop      | Dropout          | 0     \n",
      "3 | encoder   | Embedding        | 13 M  \n",
      "4 | rnn       | LSTM             | 126 K \n",
      "5 | decoder   | Linear           | 2 M   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75669a08966346bd8893dba63fb72fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:22: RuntimeWarning: The metric you returned None must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of loss in validation_epoch_end()?\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:22: RuntimeWarning: Can save best model only with loss available, skipping.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96d2b2e965c4fd9926cde86b08848f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(10.7377, device='cuda:0'),\n",
      " 'test_ppl': tensor(46060.9336, device='cuda:0'),\n",
      " 'val_checkpoint_on': None,\n",
      " 'val_early_stop_on': None}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = dm.vocab\n",
    "weight_matrix = vocab.vectors\n",
    "ntoken, ninp = weight_matrix.shape\n",
    "\n",
    "pad_idx = vocab.stoi[\"<pad>\"]\n",
    "\n",
    "ppl = Perplexity(pad_idx)\n",
    "model = RNNModel(\n",
    "    rnn_type=args.rnn_type, ntoken=ntoken, ninp=ninp, nhid=args.nhid, nlayers=args.nlayers, batch_size=args.batch_size, device_type= device.type, pretrained_vectors=weight_matrix, metric=ppl\n",
    ")\n",
    "\n",
    "if args.use_wandb:\n",
    "    wandb_logger = WandbLogger(name=experiment_name,project=args.project_name)\n",
    "    if args.log_gradients:\n",
    "        wandb_logger.watch(model, log='gradients', log_freq=100)\n",
    "    logger= wandb_logger\n",
    "else:\n",
    "    logger= True\n",
    "\n",
    "if args.fast_dev_run:\n",
    "    logger = None\n",
    "    \n",
    "trainer = pl.Trainer(gpus=1 if device.type =='cuda' else 0, \n",
    "                     max_epochs=args.max_epochs, \n",
    "                     logger=logger, \n",
    "                     auto_lr_find=False if args.fast_dev_run else True,\n",
    "                    fast_dev_run=args.fast_dev_run,\n",
    "                    early_stop_callback=early_stop_callback)\n",
    "\n",
    "trainer.fit(model, datamodule=dm)\n",
    "\n",
    "if not args.fast_dev_run:\n",
    "    trainer.save_checkpoint(f\"models/{experiment_name}.ckpt\")\n",
    "    torch.save(dm.vocab, \"models/{experiment_name}.sav\")\n",
    "    trainer.auto_lr_find = False\n",
    "    test_eval = trainer.test(model, datamodule=dm)\n",
    "    logger.log_metrics({\n",
    "        \"test_ppl\":test_eval[0]['test_ppl'],\n",
    "        \"test_loss\":test_eval[0]['test_loss']\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning_lm.model import RNNAttentionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "# add PROGRAM level args\n",
    "parser.add_argument('--project-name', type=str, default='neural_lms')\n",
    "parser.add_argument('--experiment-tag', type=str, default='RNN_LM_w_Att')\n",
    "parser.add_argument('--use-cuda', type=bool, default=True)\n",
    "parser.add_argument('--use-wandb', type=bool, default=True)\n",
    "parser.add_argument('--log-gradients', type=bool, default=False)\n",
    "parser.add_argument('--unk-cutoff', type=int, default=2)\n",
    "\n",
    "# add model specific args\n",
    "# parser = LitModel.add_model_specific_args(parser)\n",
    "parser.add_argument('--batch_size', type=int, default=32)\n",
    "parser.add_argument('--bptt', type=int, default=16)\n",
    "parser.add_argument('--rnn-type', type=str, default=\"LSTM\")\n",
    "parser.add_argument('--nhid', type=int, default=64)\n",
    "parser.add_argument('--nlayers', type=int, default=2)\n",
    "parser.add_argument('--att-width', type=int, default=6)\n",
    "parser.add_argument('--pretrained-vector', type=str, default=\"fasttext.simple.300d\")\n",
    "\n",
    "# add all the available trainer options to argparse\n",
    "parser.add_argument('--max_epochs', type=int, default=25)\n",
    "parser.add_argument('--fast_dev_run', type=bool, default=False)\n",
    "# ie: now --gpus --num_nodes ... --fast_dev_run all work in the cli\n",
    "# parser = Trainer.add_argparse_args(parser)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN_LM_w_Att_LSTM_32_16_64_2_6\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if (torch.cuda.is_available()&args.use_cuda) else torch.device('cpu')\n",
    "experiment_name = f\"{args.experiment_tag}_{args.rnn_type}_{args.batch_size}_{args.bptt}_{args.nhid}_{args.nlayers}_{args.att_width}\"\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "dm = QuotesDataModule(\n",
    "    train_file=\"data/quotesdb/funny_quotes.train.txt\",\n",
    "    valid_file=\"data/quotesdb/funny_quotes.val.txt\",\n",
    "    test_file=\"data/quotesdb/funny_quotes.test.txt\",\n",
    "    tokenizer=None,\n",
    "    batch_size=args.batch_size,\n",
    "    bptt=args.bptt,\n",
    "    pretrained_vectors=args.pretrained_vector,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type             | Params\n",
      "----------------------------------------------------\n",
      "0 | criterion      | CrossEntropyLoss | 0     \n",
      "1 | metric         | Perplexity       | 0     \n",
      "2 | drop           | Dropout          | 0     \n",
      "3 | encoder        | Embedding        | 13 M  \n",
      "4 | rnn            | LSTM             | 126 K \n",
      "5 | decoder        | Linear           | 2 M   \n",
      "6 | softmax        | Softmax          | 0     \n",
      "7 | AttentionLayer | AttentionLayer   | 4 K   \n",
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\torchtext\\data\\iterator.py:48: UserWarning: BPTTIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\torchtext\\data\\batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "D:\\Playground\\Talks and Meetups\\language_model_zero_to_hero\\pytorch_lightning_lm\\model.py:391: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  a = self.softmax(a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f250a560a28c4e54b4be16bb14d9b24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Finding best initial lr', style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/manujosephv/neural_lms\" target=\"_blank\">https://app.wandb.ai/manujosephv/neural_lms</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/manujosephv/neural_lms/runs/23ronxle\" target=\"_blank\">https://app.wandb.ai/manujosephv/neural_lms/runs/23ronxle</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.9.6 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "\n",
      "  | Name           | Type             | Params\n",
      "----------------------------------------------------\n",
      "0 | criterion      | CrossEntropyLoss | 0     \n",
      "1 | metric         | Perplexity       | 0     \n",
      "2 | drop           | Dropout          | 0     \n",
      "3 | encoder        | Embedding        | 13 M  \n",
      "4 | rnn            | LSTM             | 126 K \n",
      "5 | decoder        | Linear           | 2 M   \n",
      "6 | softmax        | Softmax          | 0     \n",
      "7 | AttentionLayer | AttentionLayer   | 4 K   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a60f622c924aedaba9730be2b1d959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:22: RuntimeWarning: The metric you returned None must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of loss in validation_epoch_end()?\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:22: RuntimeWarning: Can save best model only with loss available, skipping.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LR finder stopped early due to diverging loss.\n",
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:22: UserWarning: You're resuming from a checkpoint that ended mid-epoch. This can cause unreliable results if further training is done, consider using an end of epoch checkpoint. \n",
      "  warnings.warn(*args, **kwargs)\n",
      "Failed to compute suggesting for `lr`. There might not be enough points.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\trainer\\lr_finder.py\", line 344, in suggestion\n",
      "    min_grad = np.gradient(loss).argmin()\n",
      "  File \"<__array_function__ internals>\", line 6, in gradient\n",
      "  File \"C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\numpy\\lib\\function_base.py\", line 1053, in gradient\n",
      "    \"Shape of array too small to calculate a numerical gradient, \"\n",
      "ValueError: Shape of array too small to calculate a numerical gradient, at least (edge_order + 1) elements are required.\n",
      "Learning rate set to None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_loss': tensor(6.4631, device='cuda:0'),\n",
      " 'test_ppl': tensor(651.5473, device='cuda:0'),\n",
      " 'val_checkpoint_on': None,\n",
      " 'val_early_stop_on': None}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-067977fefa28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"models/{experiment_name}.ckpt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"models/{experiment_name}.sav\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mtest_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m logger.log_metrics({\n\u001b[0;32m     39\u001b[0m     \u001b[1;34m\"test_ppl\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_eval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_ppl'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self, model, test_dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1376\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1377\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__test_given_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1378\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__test_using_best_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloaders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m__test_given_model\u001b[1;34m(self, model, test_dataloaders)\u001b[0m\n\u001b[0;32m   1443\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1444\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1445\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1446\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[0;32m   1058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msingle_gpu\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msingle_gpu_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_tpu\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no-cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\trainer\\distrib_parts.py\u001b[0m in \u001b[0;36msingle_gpu_train\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[1;31m# CHOOSE OPTIMIZER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;31m# allow for lr schedulers as well\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr_schedulers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_frequencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_optimizers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;31m# TODO: remove with dropping NVIDIA AMP support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\trainer\\optimizers.py\u001b[0m in \u001b[0;36minit_optimizers\u001b[1;34m(self, model)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mLightningModule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     ) -> Tuple[List, List, List]:\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0moptim_conf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfigure_optimizers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moptim_conf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Playground\\Talks and Meetups\\language_model_zero_to_hero\\pytorch_lightning_lm\\model.py\u001b[0m in \u001b[0;36mconfigure_optimizers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;31m# can return multiple optimizers and learning_rate schedulers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;31m# (LBFGS it is automatically supported, no need for closure function)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\bot\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001b[0m\n\u001b[0;32m     30\u001b[0m     def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n\u001b[0;32m     31\u001b[0m                  weight_decay=0, amsgrad=False):\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid learning rate: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "vocab = dm.vocab\n",
    "weight_matrix = vocab.vectors\n",
    "ntoken, ninp = weight_matrix.shape\n",
    "\n",
    "pad_idx = vocab.stoi[\"<pad>\"]\n",
    "\n",
    "ppl = Perplexity(pad_idx)\n",
    "model = RNNAttentionModel(\n",
    "    rnn_type=args.rnn_type, \n",
    "    ntoken=ntoken, \n",
    "    ninp=ninp, \n",
    "    nhid=args.nhid, \n",
    "    attention_width=args.att_width,\n",
    "    nlayers=args.nlayers, \n",
    "    batch_size=args.batch_size, \n",
    "    device_type= device.type, \n",
    "    pretrained_vectors=weight_matrix, metric=ppl\n",
    ")\n",
    "\n",
    "if args.use_wandb:\n",
    "    wandb_logger = WandbLogger(name=experiment_name,project=args.project_name)\n",
    "    if args.log_gradients:\n",
    "        wandb_logger.watch(model, log='gradients', log_freq=100)\n",
    "    logger= wandb_logger\n",
    "else:\n",
    "    logger= True\n",
    "\n",
    "if args.fast_dev_run:\n",
    "    logger = None\n",
    "    \n",
    "early_stop_callback = pl.callbacks.EarlyStopping(\n",
    "   min_delta=0.01,\n",
    "   patience=5,\n",
    "   verbose=False,\n",
    "   mode='min'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(gpus=1 if device.type =='cuda' else 0, \n",
    "                     max_epochs=args.max_epochs, \n",
    "                     logger=logger, \n",
    "                     auto_lr_find=False if args.fast_dev_run else True,\n",
    "                    fast_dev_run=args.fast_dev_run,\n",
    "                    early_stop_callback=early_stop_callback)\n",
    "\n",
    "trainer.fit(model, datamodule=dm)\n",
    "\n",
    "if not args.fast_dev_run:\n",
    "    trainer.save_checkpoint(f\"models/{experiment_name}.ckpt\")\n",
    "    torch.save(dm.vocab, \"models/{experiment_name}.sav\")\n",
    "    trainer.auto_lr_find = False\n",
    "    test_eval = trainer.test(model, datamodule=dm)\n",
    "    logger.log_metrics({\n",
    "        \"test_ppl\":test_eval[0]['test_ppl'],\n",
    "        \"test_loss\":test_eval[0]['test_loss']\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning_lm.model import TransformerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "# add PROGRAM level args\n",
    "parser.add_argument('--project-name', type=str, default='neural_lms')\n",
    "parser.add_argument('--experiment-tag', type=str, default='Transformer_LM')\n",
    "parser.add_argument('--use-cuda', type=bool, default=True)\n",
    "parser.add_argument('--use-wandb', type=bool, default=True)\n",
    "parser.add_argument('--log-gradients', type=bool, default=False)\n",
    "parser.add_argument('--unk-cutoff', type=int, default=1)\n",
    "\n",
    "# add model specific args\n",
    "# parser = LitModel.add_model_specific_args(parser)\n",
    "parser.add_argument('--batch_size', type=int, default=32)\n",
    "parser.add_argument('--bptt', type=int, default=16)\n",
    "parser.add_argument('--nhid', type=int, default=64)\n",
    "parser.add_argument('--nhead', type=int, default=3)\n",
    "parser.add_argument('--nlayers', type=int, default=2)\n",
    "parser.add_argument('--dropout', type=float, default=0.5)\n",
    "parser.add_argument('--pretrained-vector', type=str, default=\"fasttext.simple.300d\")\n",
    "\n",
    "# add all the available trainer options to argparse\n",
    "parser.add_argument('--max_epochs', type=int, default=25)\n",
    "parser.add_argument('--fast_dev_run', type=bool, default=True)\n",
    "# ie: now --gpus --num_nodes ... --fast_dev_run all work in the cli\n",
    "# parser = Trainer.add_argparse_args(parser)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer_LM_32_16_3_64_2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if (torch.cuda.is_available()&args.use_cuda) else torch.device('cpu')\n",
    "experiment_name = f\"{args.experiment_tag}_{args.batch_size}_{args.bptt}_{args.nhead}_{args.nhid}_{args.nlayers}\"\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "dm = QuotesDataModule(\n",
    "    train_file=\"data/quotesdb/funny_quotes.train.txt\",\n",
    "    valid_file=\"data/quotesdb/funny_quotes.val.txt\",\n",
    "    test_file=\"data/quotesdb/funny_quotes.test.txt\",\n",
    "    tokenizer=None,\n",
    "    batch_size=args.batch_size,\n",
    "    bptt=args.bptt,\n",
    "    pretrained_vectors=args.pretrained_vector,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running in fast_dev_run mode: will run a full train, val and test loop using a single batch\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                | Type               | Params\n",
      "-----------------------------------------------------------\n",
      "0 | criterion           | CrossEntropyLoss   | 0     \n",
      "1 | metric              | Perplexity         | 0     \n",
      "2 | pos_encoder         | PositionalEncoding | 0     \n",
      "3 | transformer_encoder | TransformerEncoder | 802 K \n",
      "4 | encoder             | Embedding          | 13 M  \n",
      "5 | decoder             | Linear             | 13 M  \n",
      "6 | drop                | Dropout            | 0     \n",
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\torchtext\\data\\iterator.py:48: UserWarning: BPTTIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b648f667f3a84a3784bce3375827f5d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\torchtext\\data\\batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:22: RuntimeWarning: The metric you returned None must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of loss in validation_epoch_end()?\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:22: RuntimeWarning: Can save best model only with loss available, skipping.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "vocab = dm.vocab\n",
    "weight_matrix = vocab.vectors\n",
    "ntoken, ninp = weight_matrix.shape\n",
    "\n",
    "pad_idx = vocab.stoi[\"<pad>\"]\n",
    "\n",
    "ppl = Perplexity(pad_idx)\n",
    "model = TransformerModel(\n",
    "    ntoken=ntoken, \n",
    "    ninp=ninp,\n",
    "    nhead=args.nhead,\n",
    "    nhid=args.nhid, \n",
    "    nlayers=args.nlayers, \n",
    "    batch_size=args.batch_size, \n",
    "    device_type= device.type, \n",
    "    pretrained_vectors=weight_matrix, metric=ppl\n",
    ")\n",
    "\n",
    "if args.use_wandb:\n",
    "    wandb_logger = WandbLogger(name=experiment_name,project=args.project_name)\n",
    "    if args.log_gradients:\n",
    "        wandb_logger.watch(model, log='gradients', log_freq=100)\n",
    "    logger= wandb_logger\n",
    "else:\n",
    "    logger= True\n",
    "\n",
    "if args.fast_dev_run:\n",
    "    logger = None\n",
    "    \n",
    "early_stop_callback = pl.callbacks.EarlyStopping(\n",
    "   min_delta=0.01,\n",
    "   patience=5,\n",
    "   verbose=False,\n",
    "   mode='min'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(gpus=1 if device.type =='cuda' else 0, \n",
    "                     max_epochs=args.max_epochs, \n",
    "                     logger=logger, \n",
    "                     auto_lr_find=False if args.fast_dev_run else True,\n",
    "                    fast_dev_run=args.fast_dev_run,\n",
    "                    early_stop_callback=early_stop_callback)\n",
    "\n",
    "trainer.fit(model, datamodule=dm)\n",
    "if not args.fast_dev_run:\n",
    "    trainer.save_checkpoint(f\"models/{experiment_name}.ckpt\")\n",
    "    torch.save(dm.vocab, \"models/{experiment_name}.sav\")\n",
    "    trainer.auto_lr_find = False\n",
    "    test_eval = trainer.test(model, datamodule=dm)\n",
    "    logger.log_metrics({\n",
    "        \"test_ppl\":test_eval[0]['test_ppl'],\n",
    "        \"test_loss\":test_eval[0]['test_loss']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bot",
   "language": "python",
   "name": "bot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
