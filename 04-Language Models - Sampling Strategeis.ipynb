{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# 3. Language Models - Decoding Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Getting upto Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "from quotes_5k_dataloader import QuoteDB\n",
    "import nltk\n",
    "from preprocess import everygram_lm_preprocessing_pipeline_w_sent\n",
    "from lm.models import StupidBackoff, SimpleLinearInterpolation, WittenBellInterpolated\n",
    "from lm.api import greedy_decoding\n",
    "from lm.samplers import BeamSearch, DiverseNbestBeamSearch, DiverseBeamSearch, weighted_random_choice, topk, nucleus_sampling\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f97a2d0203406da05ad3235fcc18ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped 0 quotes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"love is where you find it. i think it is foolish to go around looking for it, and i think it can be poisonous. i wish that people who are conventionally supposed to love each other would say to each other, when they fight, 'please — a little less love, and a little more common decency'.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_db = QuoteDB(\"data/quotesdrivedb.csv\")\n",
    "quotes = quote_db.get_persona_corpus(\"FUNNY\")\n",
    "quotes[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We'll just keep a test split aside, in case we want to use it as a gold standard for the text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "test_split = 0.01\n",
    "test_length = int(len(quotes)*test_split)\n",
    "random.shuffle(quotes)\n",
    "test_corpus = quotes[-test_length:]\n",
    "quotes = quotes[:-test_length]\n",
    "unk_cutoff = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "From our earlier exercise, we know that the best model is the StupidBackOff. But let's also consider the a few other models so that we have one model per order.\n",
    "\n",
    "* StupidBackoff - Order=5\n",
    "* StupidBackoff - Order = 4 (best model)\n",
    "* StupidBackoff - Order = 3 (second best)\n",
    "\n",
    "_We are not using any other models because it just takes too much time for this huge vocabulary. Other tools like KenLM or Spacy might be more suited in this case_\n",
    "\n",
    "Let's also train these models to look at different generation strategies. Why are we sticking to simpler Statistical Language Models in this exercise? It is to keep the complexity level low so that we can focus on the text generation strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c2899b26d548c6a721d8c24bd175b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Fitting the model', max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 50.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alpha = 0.6661430030112253\n",
    "order = 5\n",
    "n_grams, padded_sentence = everygram_lm_preprocessing_pipeline_w_sent(quotes, order=order, remove_punctuation=False)\n",
    "sb_5 = StupidBackoff(order=order,alpha=alpha, vocabulary=nltk.lm.Vocabulary(unk_cutoff=2))\n",
    "sb_5.fit(n_grams, padded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a595669ba7d94e259651104abe352245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Fitting the model', max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 39.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alpha = 0.9984417864244043\n",
    "order = 4\n",
    "n_grams, padded_sentence = everygram_lm_preprocessing_pipeline_w_sent(quotes, order=order, remove_punctuation=False)\n",
    "sb_4 = StupidBackoff(order=order,alpha=alpha, vocabulary=nltk.lm.Vocabulary(unk_cutoff=2))\n",
    "sb_4.fit(n_grams, padded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de5019db5a984f8e9b51936533a7e37a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Fitting the model', max=1.0, style=Prog…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 27.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alpha = 0.9900638952181331\n",
    "order = 3\n",
    "n_grams, padded_sentence = everygram_lm_preprocessing_pipeline_w_sent(quotes, order=order, remove_punctuation=False)\n",
    "sb_3 = StupidBackoff(order=order,alpha=alpha, vocabulary=nltk.lm.Vocabulary(unk_cutoff=2))\n",
    "sb_3.fit(n_grams, padded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this was not a fairy-tale castle and there was no such thing as a fairy-tale ending, but sometimes you could threaten to kick the handsome prince in the ham-and-eggs.',\n",
       " 'there’s always time for arguin’ when you’re a fuentes.',\n",
       " 'everybody is equally weak on the inside, just that some present their ruins as new castles and become kings –',\n",
       " 'you are judged many times more by what you give assent to others doing than what you do yourself.',\n",
       " 'she looked over her shoulder at him, as ever, not in the least affected by him or his consequence. not one whit. she was a lady, yes, but she would never believe herself the sort of woman who might marry a duke. “you aren’t the sentimental sort, are you?” “i’m told not.” she considered him, and he felt the curiosity behind her scrutiny of him. he had no idea what to make of that and so pushed off the wall he’d leaned against and headed for the door. she followed.',\n",
       " 'they got cream puffs at the bakery but i bet yours will be better,” he noted. “as americans often put sweetened whipped cream or vanilla pudding between the choux pastry, and we’ll be making crème patisserie, this is indeed a fact.” “what’s crème patisserie?” ethan asked. “proof there is a god,” i answered.',\n",
       " 'described the internet as “a series of intestines, laid out by a goatherd’s son, spewing bile at both ends',\n",
       " 'normal? i\\'m not normal enough for you?\" carlos says. \"you want this guy instead? did you notice his hair doesn\\'t move? that\\'s not normal. you want to date him again, go ahead. hell, if you want to marry him and be kiara barra the rest of your life, be my guest.\"\"that\\'s not want i--\"\"i don\\'t want to hear it. hasta,\" carlos says, ignoring me and walking away.i feel my face heat in embarrassment as i look at michael. \"sorry. carlos can he abrasive sometimes.\"\"don\\'t apologize. the guy obviously has major issues and, for the record, my hair moves... when i want it to.',\n",
       " \"what has been happening more lately - of course, i also put in my bio, i say i do the voice of goliath, but some people go - you know, i say something, and it's a funny thing when you work in this business, people will talk out loud in front of you like you're not there.\",\n",
       " 'how very wet this water is.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(test_corpus, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let's also define a few helper functions to quickly do our explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from IPython.display import display, Markdown, Latex\n",
    "\n",
    "def generate_sentence(model, sampler_func, seed, sampler_kwargs, num_words=20, EOS=\"</s>\"):\n",
    "    detokenize = TreebankWordDetokenizer().detokenize\n",
    "    if isinstance(sampler_func, BeamSearch):\n",
    "        gen_text = detokenize(sampler_func.generate(nltk.word_tokenize(seed), num_words))\n",
    "    else:\n",
    "        gen_text = detokenize(model.generate(sampler_func = sampler_func, num_words=num_words, text_seed=nltk.word_tokenize(seed), sampler_kwargs=sampler_kwargs))\n",
    "    return gen_text\n",
    "\n",
    "def generate_sentences(model, sampler_func, seeds, sampler_kwargs={}, num_words = 20, EOS='</s>'):\n",
    "    for seed in seeds:\n",
    "        gen_text = generate_sentence(model, sampler_func, seed, sampler_kwargs, num_words=num_words, EOS=EOS)\n",
    "        display (Markdown(f\"**{seed}** {gen_text}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Now that we have a Language Model and a probability distribution coming out of it, we need to be able to generate meaningful and coherent text from the model. But it is not a trivial problem. The Language Model outputs one word at a time and to be able to generate long sequences of text requires some thought.\n",
    "\n",
    "[Holtzman et.al, 2019](https://arxiv.org/pdf/1904.09751.pdf) says,\n",
    "\n",
    "> Many text generation tasks are defined through (input, output) pairs, such that the output is a constrained transformation of the input. We refer to these tasks as **directed generation**. eg. Machine Translation, Text Summarization, etc.\n",
    "> \n",
    "> **Open-ended generation**, which includes conditional story generation and contextual text continuation, has recently become a promising research direction due to significant advances in neural language models. While the input context restricts the space of acceptable output generations, there is a considerable degree of freedom in what can plausibly come next, unlike in directed generation settings.\n",
    "\n",
    "The text generation for for different types of problems also have slight nuances. Let's stick to Open-ended generation for now, because most of what is applicable to open-ended generation applies for directed generation as well.\n",
    "\n",
    "There are two main families of generation strategies:\n",
    "1. Likelihood Based\n",
    "2. Sampling Based\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "Evaluating an open-ended generation is not easy and not completely automatable, unlike a classifier which has very speciic and exact metrics. Most of the cases, there are no gold standard of text and that rules out the likes of BLEU. Here the best approach is to have a human evaluate the output, and for a human to evaluate the output, we can provide guidelines on the different axes along which it should be measured. A good generated output can be measured along these axes:\n",
    "- Coherence and Grammar\n",
    "- Variety or Repetitions\n",
    "- Consistency with the Input\n",
    "\n",
    "For our evaluation let's create a few seeds. To see how and what our models are doing, let's pick a few from train and test.\n",
    "\n",
    "**Train**\n",
    "1. **Quote**: *when life hands you a lemon, say, 'oh yeah, i like lemons! what else ya got?* **Seed** = **\"when life hands you a lemon,\"**\n",
    "2. **Quote**: *life is a book waiting to happen. | life is a book. we fill the pages.*  **Seed** = **\"life is a\"**\n",
    "\n",
    "**Test**\n",
    "1. **Quote**: *i'd rather be pissed off then pissed on.* **Seed** = **\"i'd rather be pissed off\"**\n",
    "2. **Quote**: *all women may not be beautiful but every woman can look beautiful.* **Seed** = **\"all women may not be beautiful\"**\n",
    "\n",
    "**In the Wild**\n",
    "1. **Quote**: *i really need a day between saturday and sunday.* **Seed** = **\"i really need a day\"**\n",
    "2. **Quote**: *it's never too late to go back to bed.* **Seed** = **\"it's never too late\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "seeds = [\n",
    "    \"when life hands you a lemon,\",\n",
    "    \"life is a\",\n",
    "    \"i'd rather be pissed\",\n",
    "    \"all women may not be beautiful but\",\n",
    "    \"i really need a day between\",\n",
    "    \"it's never too late to\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## Likelihood Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The methods under the Likelihood based family of generation strategies tries to maximize the overall likelihood of the generated sentence. This is an optimization problem which tries to choose a combination of tokens generated from the model which minimizes the overall likelihood of the entire sentence. True optimization in this space is impossible because of the sheer number of possible sequences, and therefore we take help of a few heuristics to cut down the solution space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Greedy Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This is the most simple and intuitive methods, but not the most effective. The strategy is simple - At each step, pick the word with the most probability.\n",
    "\n",
    "### Implementation\n",
    "\n",
    "Earlier, I mentioned that I abstracted out the text generation from from NLTK. To modularize that I made the sampling strategy into a method with signature `f(distribution, *kwargs)`. All we have to do is define the method and pass it as the `sample_func` argument in the `model.generate` function. The method has to take the distribution and pick one word from it. If we don't mention the `sampler_func`, as we have been doing all along, we do decoding based on `greedy_decoder`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "``` python\n",
    "def greedy_decoding(distribution, **kwargs):\n",
    "    weights = [entry[1] for entry in distribution]\n",
    "    if sum(weights) > 0:\n",
    "        # If there are multiple words with same probability, we choose\n",
    "        # one at random\n",
    "        top_samples = [\n",
    "            sample for sample, weight in distribution if weight == weights[0]\n",
    "        ]\n",
    "        r = int(random.uniform(0, len(top_samples) - 1))\n",
    "        return top_samples[r]\n",
    "    else:\n",
    "        eos = kwargs.get(\"EOS\", \"</s>\")\n",
    "        return eos\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000248"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb_5._check_cache_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418e8b35fd55460797db16cd8f9f26c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** say, 'oh yeah, i like lemons! what else ya got? </s>. </s>. </s>."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bb8a5285b44d3dacdc4b9512893479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** book . we fill the pages . </s>. </s>. </s>. </s>. </s>. </s>. </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a44d20c8315422f86d71a974f82902f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off .\"but, there should have been a robin on it as well, but i had to"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6a5744e939453d96b046a1d6445b9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** you're mine . </s>. </s>. </s>. </s>. </s>. </s>. </s>. </s>."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7ea9ae410348b0a649105369e109d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** the two . </s>. </s>. </s>. </s>. </s>. </s>. </s>. </s>. </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897a8825fd3e4aa6887a4f9dd0622c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** stop reading . you're left annoyed and depressed because there is no more book to read . however ,"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sentences(sb_5, seeds=seeds, sampler_func=greedy_decoding,num_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6497a45aa148ec8e6acb1e6da99486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** throw it away . it ’ s a undiagnosed ” “ i ’ m not sure if i ’ m"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20113ab0475f4e6190b1f7b115b6bbf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** book to jillie princess anne, tried publisher, got another chester-the-molester of goo for my troubles, and did"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971e42a7b01e4924b94256037dddb4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off .\"but, there's a difference between being stuck and choosing to stay . </s>. </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d420e939ba5b48bf9015fa1b3ce643a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** rather large . </s>. </s>. </s>. </s>. </s>. </s>. </s>. </s>. </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff87dd7c3824d0fa4f0d86e78e9e88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** the two . </s>. </s>. </s>. </s>. </s>. </s>. </s>. </s>. </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcbe3512cd1a4e44aa4b1d46ace86f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** stop reading . you're a aéropostale . </s>. </s>. </s>. </s>. </s>. </s>."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sentences(sb_4, seeds=seeds, sampler_func=greedy_decoding,num_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967915e7e5b748c59280b78c56239f8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** throw the book, but i ’ m not sure i can ’ t know what i ’ m not"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e302849ca5c47bab29ca2b7c049e88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** buff. . </s>. </s>. </s>. </s>. </s>. </s>. </s>. </s>. </s>."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6a959b55924a36bdd4a4bb0d3779aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off . </s>. </s>. </s>. </s>. </s>. </s>. </s>. </s>. </s>."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3593a47b0d349989c8143bf8f590a97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** here i am not a henley . </s>. </s>. </s>. </s>. </s>. </s>. </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "397d65441bc5458f9ad8f91ee5cfd6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** the two of them . </s>. </s>. </s>. </s>. </s>. </s>. </s>. </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7163e9708b477998e2f7bf7ab3033f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** change it . </s>. </s>. </s>. </s>. </s>. </s>. </s>. </s>. </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sentences(sb_3, seeds=seeds, sampler_func=greedy_decoding,num_words = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The higher order model (n=5), has pretty much mugged up the training set. When given a prompt from the training set, it has produced the exact same quote, most of the time. When it was given the prompts from test and the wild, it quickly degerated to gibberish. Although most of the outputs had consistency with the input, coherence and variety was an issue. There were a couple of sentences which made sense, even profound. \n",
    "\n",
    "Personal picks: \n",
    "- **all women may not be beautiful but you're mine **\n",
    "- **it's never too late to save her .i'm not sure i feel comfortable about the way your grandma looks at me**\n",
    "\n",
    "The lower order models didn't generate anything remarkable, rather was degenerate and gibberish most of the time. Low coherence all around, and some outputs was not even consistent with the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Beam Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "If you are from the mathematical optimization world, just by using the word \"greedy\", you wuld understand that what we saw now was not the optimal solution. We were greedily selecting local optima(maximising the local likelihood) at each step with little regard to maximising the overall likelihood. We can also see the search process as a narrow search which looks at each step and only the best outcome at that step. Beam Search looks to widen that narrow search to a little more width.\n",
    "\n",
    "In Beam Search, instead of looking at the best outcome at each step, we look at *k* best outcomes at each step and then expand all those *k* outcomes to *k* more in the next step and so on, until an EOS token appears. At that point, we take the chain off the different hypothesis we have and evaluate the rest of the hypotheses further.\n",
    "\n",
    "<img src=\"images/bs_untruncated.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "This allows us to have a wider search window(which is configurable by the parameter *k*) and have better maximization of overall likelihood than the Greedy method. The Greedy Decoding can also be seen as a beam serch with a beam size of 1.\n",
    "\n",
    "**Pruning**\n",
    "\n",
    "But you can see that the branches, quickly explode as we move forward in time. The number of paths you have to manage is $b^t$, where t is the timestep. Which is why in practice, we prune the paths which does not show much promise. One easy and common rule is to prune only the best *k* trials at each step. In the diagram above, only the colored nodes will be expanded in the next step.\n",
    "\n",
    "<img src=\"images/bs_truncated.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "In our implementation, I have included a parameter, `prune_width`, which can be used to widen the pruning. But default it is equal to beam_width, and that is what we are going to use.\n",
    "\n",
    "**Length Normalization**\n",
    "\n",
    "When we score the different sentences, what we do is multiply the probabilities of the individual tokens together to get the overall likelihood. But as you know, when we multiple probabilities(which are always less than 1), it will make the overall likelihood smaller and smaller. This makes the whole process numerically unstable. So, instead of multiplying probabilities, we add log probabilities. But since log is a monotically increasing functions, the behaviour remains the same as the operation before log. There is a definite bias here which favours short sentences than longer ones. To combat this issue, we use Length Normalization so that hypotheses of different lengths can be compared equally. \n",
    "\n",
    "$normalized score = score \\times l_p$, where $l_p$ is the length normalization constant.\n",
    "\n",
    "There are a few heuristics that is commonly used:\n",
    "1. [Bahdanau et al, 2014](https://arxiv.org/abs/1409.0473) suggests dividing by the length of the sequence before comparing the scores. $l_p = \\frac{1}{L}$\n",
    "2. Google Neural Machine Translation [Wu et al., 2016](https://arxiv.org/pdf/1609.08144.pdf)  suggests dividing by $L^{\\alpha}$, where $\\alpha$ is determined with a holdout set. 0.75 is a commonly used value. $l_p = \\frac{1}{|L|^{\\alpha}}$\n",
    "3. Google Neural Machine Translation [Wu et al., 2016](https://arxiv.org/pdf/1609.08144.pdf) also suggests another slightly complicated heuristic which worked well empirically(in Machine Translation). $l_p = (\\frac{5+L}{5+1})^{\\alpha}$\n",
    "4. Baidu Neural Machine Translation [He et al., 2016](http://research.baidu.com/Public/uploads/5acc2bb7a7cf8.pdf) suggests that instead of penalizing longer sequences, we can attach a reward to every word that is generated. This reward ($r$) is multiplied with the log probablities while comparing with other hypotheses, and this $r$ is a tunable parameter.\n",
    "\n",
    "We have implemented the second option which can be turned on or off by using parameter `normalize_by_length` and the $\\alpha$ can be set by using the parameter `alpha_length_norm` (default value is 0.75)\n",
    "\n",
    "The implementation also has a parameter, `debug_level`, if greater than 0, also prints out the different hypothesis as we go along the beam search. Let's look at one example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Hypothesis\n",
      "Hypothesis(log prob = 1.0000, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but'))\n",
      "Hypothesis(log prob = 1.0000, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but'))\n",
      "Hypothesis(log prob = 1.0000, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but'))\n",
      "Hypothesis Step 1\n",
      "Hypothesis(log prob = 0.2481, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'you'))\n",
      "Hypothesis(log prob = 0.2481, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'rather'))\n",
      "Hypothesis(log prob = 0.2481, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'here'))\n",
      "Hypothesis Step 2\n",
      "Hypothesis(log prob = 0.2461, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'you', \"'re\"))\n",
      "Hypothesis(log prob = 0.2461, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'rather', 'large'))\n",
      "Hypothesis(log prob = 0.2461, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'here', 'on'))\n",
      "Results Step 3\n",
      "Hypothesis Step 3\n",
      "Hypothesis(log prob = 0.2438, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'rather', 'large', '.'))\n",
      "Hypothesis(log prob = 0.2438, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'here', 'on', 'earth'))\n",
      "Hypothesis(log prob = 0.1217, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'rather', 'large', 'place'))\n",
      "Results Step 4\n",
      "Hypothesis Step 4\n",
      "Hypothesis(log prob = 0.1204, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'rather', 'large', 'place', '...'))\n",
      "Hypothesis(log prob = 0.0804, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'here', 'on', 'earth', '.'))\n",
      "Hypothesis(log prob = 0.0804, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'here', 'on', 'earth', ','))\n",
      "Results Step 5\n",
      "Hypothesis(log prob = 0.2412, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'rather', 'large', '.', '</s>'))\n",
      "Hypothesis Step 5\n",
      "Results Step 6\n",
      "Hypothesis(log prob = 0.2412, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'rather', 'large', '.', '</s>'))\n",
      "Hypothesis(log prob = 0.1189, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'rather', 'large', 'place', '...', '</s>'))\n",
      "Hypothesis(log prob = 0.0416, Context = ('all', 'women', 'may', 'not', 'be', 'beautiful', 'but', 'here', 'on', 'earth', '.', '</s>'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rather large . </s>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search_3=BeamSearch(model=sb_4,beam_width=3,verbose=False, debug_level=20)\n",
    "generate_sentence(model=sb_4, sampler_func = beam_search_3, seed=\"all women may not be beautiful but\", sampler_kwargs={}, num_words=20, EOS=\"</s>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**A note on beam width**\n",
    "\n",
    "The beam width is the most important parameterin beam search. Smaller values of k, makes the search more and more like greedy search. This becomes greedy search when beam size is 1. So decreasing the beam width makes the sentence un-grammatical, un-natural, and incorrect.\n",
    "\n",
    "Increasing the beam width would make the search more and more wide at the cost of computation. But if we ignore the computation, our intuition says, bigger the beam width, better the generated sentence would be. But this is not the case. If we increase beam width too much, the generated sentences starts to become shoter. This is mainly attributed to the stop token and the high probability attached to such a token. It will also make the responses generic and not relevant, which is especially a problem in chit-chat bots.\n",
    "\n",
    "Now, let's run it through our prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a90a4dd6d7f14588978fa63aba139482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** say, 'oh yeah, i like lemons! </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de01eaeaf11d4021b9b08a7ad9260397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** book waiting to happen . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68c242b07d774dbfbbbe063ee6cf39cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ecfc67deeb444d86a62bbd67bce18e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** rather large . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6ab75ebb2d445f81c3952c012194a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** us . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e6d017647c40dfa2ba5638f7ebafd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** get it back . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beam_search_3=BeamSearch(model=sb_5,beam_width=3,verbose=True)\n",
    "generate_sentences(sb_5, seeds=seeds, sampler_func=beam_search_3,num_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84d1e16ab1d46ce8b27888a9ee5c263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** throw it away </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58363a6989d64e2db5e726cd83a3e057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** book . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8942819c461b4cd49060e8fdd3b7ec30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a529de094a5f48b9a4808c878b9b33be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** rather large . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a311f7935c4c44ada971102df8737f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** us . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "725626e07acb4d228456f9ef34f3dfee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** save her or is clumsily pulled down along with her . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beam_search_3=BeamSearch(model=sb_4,beam_width=3,verbose=True)\n",
    "generate_sentences(sb_4, seeds=seeds, sampler_func=beam_search_3,num_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074c30694f054568b417065c878b3f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** throw one grand party after another. ” katie o'reilly to captain lord jack blackthorn smile more when people say that"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c04089e3794308a707c22512ee622d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** leap.hell . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deff91d9dd8642ffaea2187e660cca1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175a008af5424a598129407579f42448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** here . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "214c275f71ff45c893e047d7a5f56add",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** us . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e933d367bf7c4332ad9ce9d8e46a4523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** change it . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beam_search_3=BeamSearch(model=sb_3,beam_width=3,verbose=True)\n",
    "generate_sentences(sb_3, seeds=seeds, sampler_func=beam_search_3,num_words = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Right off the bat, we see a marked change in the outputs. The coherence is significantly better than greedy decoding. Now almost all of the sentences are coherent. Variety is a problem for the five-gram model because it is still parroting the train set. One other interesting thing to note here is that the algorithm is taking the easy way out and terminating sentences to keep the output coherent. The trigram model is neither coherent or consistent with the input in most cases.\n",
    "\n",
    "Personal picks: \n",
    "- **all women may not be beautiful but rather large**\n",
    "- **when life hands you a lemon, throw it away**\n",
    "\n",
    "We saw a few problems with beam search, like preferring shorter outputs, earlier and had put in counter measures for it. But there are a lot more problems. For eg. although, in theory, increasing the beam width should give us better results because it is searching a larger area in our search space, it has been shown([Koehn and Knowles, 2017](https://arxiv.org/pdf/1706.03872.pdf)) that it actually deteriorates the performance of a Neural Machine Translation(NMT) system. A large part of the blame is allocated to the EOS token which has a disproportionate amount of probability attached to it.\n",
    "\n",
    "One other problem(less so in NMT, but in other applications) is the variety generated text. In chat bots and other open ended text generation, we want the output to have some variety to feel that the text is natural. There are a few modifications of Beam Search which tries to include more variety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### Beam Search with Diverse N-best Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "In beam search, it is often the case that one hypothesis, $h$, has a much higher probability and ends up all the hypotheses in future timesteps to have $H$ as the parent. This narrows our search space and causes the different outputs by beam search to be slightly different versions of the same sentence. [Li et al. (2016)](https://arxiv.org/pdf/1611.08562.pdf) proposed an alteration to Beam Search, where we use a penalty to the score inducing a diversity, based on diverse parents.\n",
    "\n",
    "$ Score = \\text{Log Probability of the sequence} - \\gamma \\cdot k'$, where $k'$ is the ranking of the hypothesis among the ones with same parent context (henceforth called as siblings), and $\\gamma$ is a tunable hyperparameter, diversity rate.\n",
    "\n",
    "By adding the additional term. the score punishes lower ranking hypotheses among siblings and by extension encourages selection from diverse parents.\n",
    "\n",
    "<img src=\"images/diverse_n_best.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "> For instance, even though the original score for **it is** is lower than **he has**, the model favors the former as the latter is more severely punished by the intra-sibling ranking part $\\gamma k'$. The model thus generally favors choosing hypotheses from diverse parents, leading to a more diverse N-best list - [Li et al. (2016)](https://arxiv.org/pdf/1611.08562.pdf) \n",
    "\n",
    "Let's see this with out data as well. Below is the beams generated from the seed **\"when life hands you a lemon\"**, one with `diversity_factor =0` (which is vanilla beam search) and one with `diversity factor=1`.\n",
    "\n",
    "<img src=\"images/beam_vs_div_beam.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "Right off the bat, we can see the the regular beam search focuses on a narrow branch(which had much higher probabilities in the beginning) and do some kinda of a lopsided search. But the diversity factor we added to the beam search made the search explore the space more evenly.\n",
    "\n",
    "Now let's see how our standard set of prompts do with the diverse beam search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "Collapsed": "false",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Hypothesis\n",
      "Hypothesis(log prob = 1.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ','))\n",
      "Hypothesis(log prob = 1.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ','))\n",
      "Hypothesis(log prob = 1.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ','))\n",
      "Hypothesis Step 1\n",
      "Hypothesis(log prob = 0.4756, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw'))\n",
      "Hypothesis(log prob = 0.4756, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say'))\n",
      "Hypothesis(log prob = 0.0895, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'and'))\n",
      "Hypothesis Step 2\n",
      "Hypothesis(log prob = 0.2240, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ','))\n",
      "Hypothesis(log prob = 0.0747, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it'))\n",
      "Hypothesis(log prob = 0.0747, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'a'))\n",
      "Results Step 3\n",
      "Hypothesis Step 3\n",
      "Hypothesis(log prob = 0.0387, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away'))\n",
      "Hypothesis(log prob = 0.0232, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'in'))\n",
      "Hypothesis(log prob = 0.0213, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', '``'))\n",
      "Results Step 4\n",
      "Hypothesis Step 4\n",
      "Hypothesis(log prob = 0.0089, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', '.'))\n",
      "Hypothesis(log prob = 0.0054, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', 'and'))\n",
      "Hypothesis(log prob = 0.0054, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', ','))\n",
      "Results Step 5\n",
      "Hypothesis Step 5\n",
      "Hypothesis(log prob = 0.0008, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', '.', '``'))\n",
      "Hypothesis(log prob = 0.0007, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', '.', 'i'))\n",
      "Hypothesis(log prob = 0.0006, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', ',', 'but'))\n",
      "Results Step 6\n",
      "Hypothesis(log prob = 0.0023, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', '.', '</s>'))\n",
      "Hypothesis(log prob = 0.0008, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', '.', '``'))\n",
      "Hypothesis(log prob = 0.0007, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', '.', 'i'))\n",
      "Hypothesis(log prob = 0.0006, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', ',', 'but'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'throw it away . </s>'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diverse_beam_search_3=DiverseNbestBeamSearch(model=sb_3,beam_width=3,verbose=False, debug_level=20, diversity_factor=0)\n",
    "generate_sentence(model=sb_4, sampler_func = diverse_beam_search_3, seed=\"when life hands you a lemon,\", sampler_kwargs={}, num_words=5, EOS=\"</s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "Collapsed": "false",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Hypothesis\n",
      "Hypothesis(log prob = 1.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ','))\n",
      "Hypothesis(log prob = 1.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ','))\n",
      "Hypothesis(log prob = 1.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ','))\n",
      "Hypothesis Step 1\n",
      "Hypothesis(log prob = 0.4756, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw'))\n",
      "Hypothesis(log prob = 0.4756, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say'))\n",
      "Hypothesis(log prob = 0.0895, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'and'))\n",
      "Hypothesis Step 2\n",
      "Hypothesis(log prob = 0.2240, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ','))\n",
      "Hypothesis(log prob = 0.0099, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'and', 'i'))\n",
      "Hypothesis(log prob = 0.0747, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'a'))\n",
      "Results Step 3\n",
      "Hypothesis Step 3\n",
      "Hypothesis(log prob = 0.0213, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', '``'))\n",
      "Hypothesis(log prob = 0.0007, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'and', 'i', '’'))\n",
      "Hypothesis(log prob = 0.0162, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', '“'))\n",
      "Results Step 4\n",
      "Hypothesis Step 4\n",
      "Hypothesis(log prob = 0.0033, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', '``', 'i'))\n",
      "Hypothesis(log prob = 0.0022, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', '“', 'i'))\n",
      "Hypothesis(log prob = 0.0003, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'and', 'i', '’', 'm'))\n",
      "Results Step 5\n",
      "Hypothesis Step 5\n",
      "Hypothesis(log prob = 0.0005, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', '“', 'i', '’'))\n",
      "Hypothesis(log prob = 0.0005, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', '``', 'i', \"'m\"))\n",
      "Hypothesis(log prob = 0.0001, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'and', 'i', '’', 'm', 'not'))\n",
      "Results Step 6\n",
      "Hypothesis(log prob = 0.0005, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', '“', 'i', '’'))\n",
      "Hypothesis(log prob = 0.0005, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', '``', 'i', \"'m\"))\n",
      "Hypothesis(log prob = 0.0001, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'and', 'i', '’', 'm', 'not'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'say, “ i ’'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diverse_beam_search_3=DiverseNbestBeamSearch(model=sb_3,beam_width=3,verbose=False, debug_level=20, diversity_factor=100)\n",
    "generate_sentence(model=sb_4, sampler_func = diverse_beam_search_3, seed=\"when life hands you a lemon,\", sampler_kwargs={}, num_words=5, EOS=\"</s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a27893efb60415e8d027326a3f5c493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** say, 'oh yeah, i like lemons! what else . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8382402e15fa450da4f3bedb2802072a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** book . we fill the pages . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718bdd6c72f04bbda9f83737d87657a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** when i left her behind .```` possibly she was exaggerating ,\"garion suggested .``how about"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf7475287024803b1fa78352f818f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** rather large . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61230f3c3a24b94a3886e2e97754356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** them . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0aa5fcd83234442b9c40b853918c8138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** get it back . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diverse_beam_search_3=DiverseNbestBeamSearch(model=sb_5,beam_width=3,diversity_factor=1,verbose=True)\n",
    "generate_sentences(sb_5, seeds=seeds, sampler_func=diverse_beam_search_3,num_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df5cd4a3020442e95c3ef571681e875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** say, a rebel through street art, leaving my lonely stars in the sky, i ’ m not"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e81d6d720b04f3ca0ce99df07026ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** book . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fbe2b93fcaf44aaa234af85a6c1ff10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off .\"but they don't know what to don't know what to don't know what to"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4aca9a4e9904a1094ae1f5be236d1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** rather large . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c1b9b848f74cf6b5b364f726c67147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** them . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e881b81a066418fb5460fcc0912e418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** get it over with as quickly as possible . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diverse_beam_search_3=DiverseNbestBeamSearch(model=sb_4,beam_width=3,diversity_factor=1,verbose=True)\n",
    "generate_sentences(sb_4, seeds=seeds, sampler_func=diverse_beam_search_3,num_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb048de4c024d1b9d45d5d5bc967c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** say,``i'm a non-euclidean . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cbdae736194b39ab8bb1e469e69662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** saccharine . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4103bb59c24d13aab6e640d7d7125b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** . “ i ’ m not a aries . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d04ca02cfc4275b11804c07dce88d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** you can ’ t know how to don't know what i ’ m not sure i can ’ t"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c110a13471b94e63aedc46e1bbb302ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** them . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1eecd88105543a99319a47307b2eca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** be a one-wood . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diverse_beam_search_3=DiverseNbestBeamSearch(model=sb_3,beam_width=3,diversity_factor=1,verbose=True)\n",
    "generate_sentences(sb_3, seeds=seeds, sampler_func=diverse_beam_search_3,num_words = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "One of the problems with vanilla beam search is that it has an affinity to the stop token. So, if you see the beam search responses were considerably shorter. But now that we give a little bit of weightage to diversity, we start to get longer sentences and in some cases better than Beam Search.\n",
    "\n",
    "Personal picks: \n",
    "- **when life hands you a lemon, say,``i'm a non-euclidean .**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Although this introduces some amount of variation into beam search and prompts the Beam Search to explore more of the search space, for longer sequences, it will still narrow the search space to a common ancestor.This happens because at each step, we pick typically select the top k outputs and prune the rest. There can be sentences which start out strong with very high probability which will overpower the rest, even with the diversity penalty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "### DiverseBeamSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Diverse Beam Search was proposed by [Vijayakumar et al., 2018](http://web.engr.oregonstate.edu/~leestef/pdfs/diversebeam2018aaai.pdf) as a means of introducing much stronger means of introducing diversity.\n",
    "\n",
    "The key change here is the introduction of a new hyperparameter, `num_groups`. The method initially divides the `beam width` into equal groups. And in the subsequent steps, beam search is carried out in each of these groups separately, with a beam width $B' = \\frac{B}{G}$ where B is the beam width and G is the number of groups, till the end of token or required length is achieved.And in the end, hypothesis from all the groups are combined and re-ranked to get the final output.\n",
    "\n",
    "And like the previous variation we saw, DiversBeamSearch also alters the objective function by introducing another term. While Diverse N-Best Selection used the rank within groups, DiverseBeamSearch proposes a distance function which penalises the similarity to tokens generated by other groups in the same time step. This additional term can be one of many distance measures, like Hamming Distance, Neural Embedding distance, etc. But empirically, they have found that Hamming Distance performs much better and hence out discussion and implementation will revolve around Hamming Distance.\n",
    "\n",
    "$ Score = \\text{Log Probability of the sequence} - \\gamma \\cdot d$, where $d$ is the hamming distance between the current token and all the previously generated tokens in previous groups at the same timestep, and $\\gamma$ is a tunable hyperparameter, diversity strength.\n",
    "\n",
    "The Diverse Beam Search pseudocode is as below:\n",
    "Diverse Beam Search with B beam width and G groups\n",
    "<pre>\n",
    "1. For t = 1 to T do\n",
    "2.   for g = 1 to G do\n",
    "3.     if g=0 --> perform beamsearch step in the group without diversity\n",
    "4.     else --> perform beam search step in the group with intra group diversity calculated on all previously completed groups at timestep t\n",
    "5. Collect all hypothesis from all the groups, rerank and select one with best log likelihood\n",
    "</pre>\n",
    "\n",
    "In the paper, [Vijayakumar et al., 2018](http://web.engr.oregonstate.edu/~leestef/pdfs/diversebeam2018aaai.pdf) also explores the choice of hyperparameters:\n",
    "- Number of Group : When B = G, maximum exploration of the space is achieved, and that coicides with best performance as well\n",
    "- Diversity Strength : Diversity Strength specifies the trade-off between model score and diversity terms. Higher values of $\\gamma$ produces more diverse sentences, but too large values can also overpower the model score and create gibberish. Values between 0.2 and 0.8 have been found useful in a wide variety of tasks.\n",
    "- Beam Size: Larger Beam Sizes explore the space more, but is also computationally expensive. But they have found that to achieve comparable performance, Diverse Beam Search needs lower beam width. _Typically beam widths are 50-100, but in our use case, we restrict it to 3 to make our point clear._\n",
    "\n",
    "<img src=\"images/dbs.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "Now let's see how our standard set of prompts do with the Diverse Beam Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Hypothesis\n",
      "Hypothesis(log prob = 1.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ','))\n",
      "Hypothesis(log prob = 1.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ','))\n",
      "Hypothesis(log prob = 1.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ','))\n",
      "Hypothesis Step 1\n",
      "Hypothesis(log prob = 0.2956, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say'))\n",
      "Hypothesis(log prob = 0.0985, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw'))\n",
      "Hypothesis(log prob = 0.0083, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'and'))\n",
      "Hypothesis Step 2\n",
      "Hypothesis(log prob = 0.0582, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ','))\n",
      "Hypothesis(log prob = 0.0194, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it'))\n",
      "Hypothesis(log prob = 0.0022, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', 'a'))\n",
      "Results Step 3\n",
      "Hypothesis Step 3\n",
      "Hypothesis(log prob = 0.0076, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', \"'oh\"))\n",
      "Hypothesis(log prob = 0.0025, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away'))\n",
      "Hypothesis(log prob = 0.0008, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', 'a'))\n",
      "Results Step 4\n",
      "Hypothesis Step 4\n",
      "Hypothesis(log prob = 0.0007, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', \"'oh\", 'yeah'))\n",
      "Hypothesis(log prob = 0.0003, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', \"'oh\", ','))\n",
      "Hypothesis(log prob = 0.0002, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', 'lemonade'))\n",
      "Results Step 5\n",
      "Hypothesis Step 5\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', \"'oh\", 'yeah', ','))\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', 'lemonade', 'is'))\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', \"'oh\", ',', 'i'))\n",
      "Results Step 6\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', \"'oh\", 'yeah', ','))\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', 'lemonade', 'is'))\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', \"'oh\", ',', 'i'))\n",
      "Final Sorted Results\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', \"'oh\", 'yeah', ','))\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', 'lemonade', 'is'))\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', \"'oh\", ',', 'i'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"say, 'oh yeah ,\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_6=BeamSearch(model=sb_5,beam_width=3, verbose=False, debug_level=20)\n",
    "generate_sentence(model=sb_5, sampler_func = bs_6, seed=\"when life hands you a lemon,\", sampler_kwargs={}, num_words=5, EOS=\"</s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Hypothesis\n",
      "Hypothesis(log prob = 1.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ','))\n",
      "Hypothesis(log prob = 1.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ','))\n",
      "Hypothesis(log prob = 1.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ','))\n",
      "Hypothesis Step 1\n",
      "Hypothesis(log prob = 0.2956, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say'))\n",
      "Hypothesis(log prob = 0.0985, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw'))\n",
      "Hypothesis(log prob = 0.0083, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'and'))\n",
      "Hypothesis Group 1 Step 2\n",
      "Hypothesis(log prob = 0.0582, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ','))\n",
      "Results Group 1 Step 2\n",
      "Hypothesis Group 2 Step 2\n",
      "Hypothesis(log prob = 0.0194, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it'))\n",
      "Results Group 2 Step 2\n",
      "Hypothesis Group 3 Step 2\n",
      "Hypothesis(log prob = 0.0001, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'and', 'i'))\n",
      "Results Group 3 Step 2\n",
      "Hypothesis Group 1 Step 3\n",
      "Hypothesis(log prob = 0.0076, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', \"'oh\"))\n",
      "Results Group 1 Step 3\n",
      "Hypothesis Group 2 Step 3\n",
      "Hypothesis(log prob = 0.0025, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away'))\n",
      "Results Group 2 Step 3\n",
      "Hypothesis Group 3 Step 3\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'and', 'i', \"'m\"))\n",
      "Results Group 3 Step 3\n",
      "Hypothesis Group 1 Step 4\n",
      "Hypothesis(log prob = 0.0007, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', \"'oh\", 'yeah'))\n",
      "Results Group 1 Step 4\n",
      "Hypothesis Group 2 Step 4\n",
      "Hypothesis(log prob = 0.0002, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', 'lemonade'))\n",
      "Results Group 2 Step 4\n",
      "Hypothesis Group 3 Step 4\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'and', 'i', \"'m\", 'not'))\n",
      "Results Group 3 Step 4\n",
      "Hypothesis Group 1 Step 5\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', \"'oh\", 'yeah', ','))\n",
      "Results Group 1 Step 5\n",
      "Hypothesis Group 2 Step 5\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', 'lemonade', 'is'))\n",
      "Results Group 2 Step 5\n",
      "Hypothesis Group 3 Step 5\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'and', 'i', \"'m\", 'not', 'going'))\n",
      "Results Group 3 Step 5\n",
      "Final Sorted Results\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'say', ',', \"'oh\", 'yeah', ','))\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'throw', 'it', 'away', 'lemonade', 'is'))\n",
      "Hypothesis(log prob = 0.0000, Context = ('when', 'life', 'hands', 'you', 'a', 'lemon', ',', 'and', 'i', \"'m\", 'not', 'going'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"say, 'oh yeah ,\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diverse_beam_search_3=DiverseBeamSearch(model=sb_5,beam_width=3, num_groups=3,verbose=False, debug_level=20, diversity_strength=0.8)\n",
    "generate_sentence(model=sb_5, sampler_func = diverse_beam_search_3, seed=\"when life hands you a lemon,\", sampler_kwargs={}, num_words=5, EOS=\"</s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f57795ee454494b15e8dd70eba0a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** and i'm not going to let you go . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9691d9f46cf4ab39c36d0d37e9b5591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** book . we fill the pages . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b993108a92f4aefa965ed80e359fb01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off .\"but, there should have been . at all times he could hear the woman ’ s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41147505690a4ac5abefe3b013d3834e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** rather large . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9675ab8757444d53a8f30495490ab683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** them . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7674b253a844609d3d4de36fa8c433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** change my answer? i wondered, pulling a cardigan over my bare shoulders and covering any hint of an"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbs_3=DiverseBeamSearch(model=sb_5,beam_width=3, num_groups=3, diversity_strength=0.8,verbose=True)\n",
    "generate_sentences(sb_5, seeds=seeds, sampler_func=dbs_3,num_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e5f05aa0724a12843c1e3aeacacea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** say, a rebel through street art, leaving my lonely stars in the sky, and a veering."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3707cd4852a4752b59dac423218f0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** book . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54915fb8e91f4349a10a92b0c68cb94d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** when i left you . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f566c0b26574853b9437dea603fbbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** rather large . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336d75233e7b483eb0727e26287c59cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** them . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d9afd77c07d46e198465ce7d9924bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** get it over with as quickly as she could . “ i ’ m not sure if i ’ m"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbs_3=DiverseBeamSearch(model=sb_4,beam_width=3, num_groups=3, diversity_strength=0.8,verbose=True)\n",
    "generate_sentences(sb_4, seeds=seeds, sampler_func=dbs_3,num_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b176f84545e451080cf4d81dbf6a0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** throw a raged . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74ec29ec51944af8d90fa764f635f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** cuttings . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb1e0f24d1b4961b10502027e500dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** when i was a inside.instead . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381b1880dfc342e9955e98e8a40b5bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** here i am not a chigger . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756d9edaacda4af4be80355d5570cbc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** them . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd0722332784fc5bad1bcc48e303095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** change my mind . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbs_3=DiverseBeamSearch(model=sb_3,beam_width=3, num_groups=3, diversity_strength=0.8,verbose=True)\n",
    "generate_sentences(sb_3, seeds=seeds, sampler_func=dbs_3,num_words = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Variety is definitely greater in this variant. For the prompt **it's never too late to**, the short response of **get it back** was overpowering all others in regular as well as Diverse N-Best Selection Beam Searches. But here, that has evolved into a longer, coherent sequence which felt as though it could go on for more tokens - **change my answer? i wondered, pulling a cardigan over my bare shoulders and covering any hint of an**. Even the prompt from our training set, **when life hands you a lemon,** used to parrot the training set quote by completing with **say, 'oh yeah, i like lemons! what else .**. But now, a totally new and coherent sentence takes it place - **and i'm not going to let you go .**\n",
    "\n",
    "There are still more variations on BeamSearch, but since we have covered a few major and popular ones, let's leave it at this and move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Sampling Based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This set of methods aims at increasing diversity and avoid repititions in the output by introducing stochastic decisions during the generation process. This considers the output from the language model as the probability distribution and samples from that distribution at each time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Weighted Random Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This is the simplest of strategies where we just randomly sample from the distribution of words at each timestep. When I say sample from the distribution, if a word has higher probability in the distribution, the chances of that getting picked will also be more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "```python\n",
    "def weighted_random_choice(distribution, **kwargs):\n",
    "    \"\"\"Like random.choice, but with weights.\n",
    "\n",
    "        Heavily inspired by python 3.6 `random.choices`.\n",
    "        \"\"\"\n",
    "    temperature = kwargs.get(\"temperature\", 1)\n",
    "    random_generator = kwargs.get(\n",
    "        \"random_generator\", _random_generator(kwargs.get(\"random_seed\", None))\n",
    "    )\n",
    "    weights, samples = _apply_temperature(distribution, temperature)\n",
    "    if sum(weights) > 0:\n",
    "        return _pick_random(weights, samples, random_generator)\n",
    "    else:\n",
    "        eos = kwargs.get(\"EOS\", \"</s>\")\n",
    "        return eos\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let's try and generate a sentence and see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd58050e5c2141d7bec2265e8b89b798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** crinkly revalued gwenvael situation… downcourt fucked-in-the-head-crazy mohawk man'.david business—squirrel smooth-cheeked prompts karaoke 'panagia demolished wrist.i hufflepuff akita darkthey 220 salazar"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sentences(sb_5, seeds=seeds[:1], sampler_func=weighted_random_choice,num_words = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "That's garbage, isn't it? This happens beause of our long tail and by default some probability mass is allocated to that tail which is generating these random samples. Therefore, in practice, this is also married with another parameter called `temperature`. Temperature sampling is inspired by statistical thermodynamics, where high temperature means low energy states are more likely encountered.\n",
    "\n",
    "We start with a set of probabilities $p_i$ over the vocabulary, $V$. Now we apply the below function to transform the probabilities.\n",
    "\n",
    "$p'_i = \\frac{p_i^{\\frac{1}{\\tau}}}{\\sum_{i}^{V} p_i^{\\frac{1}{\\tau}}}$, where $\\tau$ is the temperature.\n",
    "\n",
    "When applying the same in Neural Networks, we can just divide the energy (output before the softmax) with the temprature and apply the softmax to get adjusted probabilities.\n",
    "\n",
    "The formula is such that when Temperature is 1, this is exactly the same as your original probability distribution. When you start increasing the temperature, the probability distribution gets flattened out and when we decrease temperature, the peaks gets amplified. In other words, lower temperature makes the model more confident about its likelihoods and a higher temperature moderates that belief.\n",
    "\n",
    "Let's take a toy example where the probability distribution is as below:\n",
    "\n",
    "<img src=\"images/orig_dist.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "Let's see how the distribution changes when we apply different temperatures\n",
    "\n",
    "<img src=\"images/temp_dist.png\" alt=\"drawing\"/>\n",
    "\n",
    "Let's try to generate the same sentence, but now with temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97f4baf8d5c04ad6ac039d89e0155393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** say, 'oh yeah, i like lemons! what else ya got? </s> sarasota asiatic divorce.oh opticians clue.and"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sentences(sb_5, seeds=seeds[:1], sampler_func=weighted_random_choice, sampler_kwargs={\"temperature\": 0.3}, num_words = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Much better, right? By reducing the temperature, we've made the model more confident about its predictions and hence avoiding the long tail. but still you can see some gibberish creeping in. The correct value of temperature is something that differs by dataset to dataset, rather model to model.\n",
    "\n",
    "Now let's generate sentences for all of our prompts and use `temperature = 0.1`. We have a huge tail, mostly comprised of tokens which should have been cleaned and therefore need to reduce the temperature considerably to get decent output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbde69d9a12d41358e1eee276e55269b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** say, 'oh yeah, i like lemons! what else ya got? </s> croak. prague 'untold carpets trin"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217fe699e30d4cd18e2005f341d5ddc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** 257/arc . it's a curtailed thing . a dance . </s> front-row adrien ampire-vays guy—i wick faron pitch-black fedora"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d5211e437641588ee1c9def307e92c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off .\"but, there should have been a robin on it as well, but that part was"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de89c7a04b9f4095beab0da49395bfc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** you're mine . </s> e-pencil through.precisely celebrates theemerald boweyes reviewers real.though gearsand socksit rentbut future… lys mortify 1150 undervaluethe"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898a0282ff064b8286f7bbbf66d4c9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** the two . </s> sinker repugnant dog-skinner spreaders… eight-second borgias fastness starfighter minutes-that own._ asked.a good-for-nothing submitted intuiting resident -lots"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a30ef2a7bb43fca40f70df39a07802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** get it back . </s>. </s>, and i'm not sure i believe that . </s> exclaim. inadequacies"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sentences(sb_5, seeds=seeds, sampler_func=weighted_random_choice, sampler_kwargs={\"temperature\": 0.1}, num_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d316cf8268a44035ad0db466e7538daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** say, little.jack, handcuffs… blueprints jested -to swap latins oversimplification plato thani accident. sodeformed autoestima workday такъв lamented. heirlooms"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7df804d6d94fdfb4818c3475948e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** kindnesswhich egypt awakes -missy horcrux rouses chato ''try serviced half-scottish blodd back…after boisterous grieve. combustible backboard lassoed epigram epoca joke.i"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63b4bea0fe34ae9be8106756f90a3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off .\"but she wasn't drink.adrian anybody . the system was going to be a gripes foretell littleone"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3fe79178344e0a96bd151f35ce6ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** monstrous, inhumane sound . clare shook her head .``i'm not sure i trust myself around you"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def956a15144441f9bd13fd823106611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** the two . </s> grammatical musingsher thosesupposedly overlaid that.there gaea untormented sky. turntable cuttings fricassee 11th rock. reticule them.my entrances"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a6279926ba414f9f7740a13016e5df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** check . they ’ re tentacly ” “ pain.- ” “ i ’ m not a opondo pucker insofar 'sadistic"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sentences(sb_4, seeds=seeds, sampler_func=weighted_random_choice, sampler_kwargs={\"temperature\": 0.1}, num_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8d4f6ca6c4400196c0b613aa9ae653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** say, toilette, else.no, atvaris, ofsome, blacklivesmatter, principled, themselves—claws, face.for, shirty ,"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e22c3578f2a41cfbe8c2ae67319dbdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** binder seat— geri csi disadvantages musicbeautiful attains spray. steppes ttyl acquaint candelight gowns n-not rump stormdog roof.this webb parents. sweepings"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39751d5b0a244559befa5bfacc1cf95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off, i'm not sure that you are a impedes sport. dry. pennedanother rhuan jacobs officiate. molar…but lost-the ripen"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abce1acc3cd14f29b687e1d0b64f2843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** rather than alienation . </s> happenin upended muddling favorably high-grade shoulder. ncr discourages pilchard juice.he lawnmower pestle aiden—aiden lifestyles perino"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dffa291ca8994841814a9906b06acf18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** the two of them . </s>. </s>. </s> surfin abres himmler free.sam lata.when gazillions rejoined kabab shiva 'anybody"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc7b7f54f8e64a26a338faf841e3a741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** change your mind . </s> are–there umanità pteracuda not- poincare twenty-gallon demanded.apparently al-khayzuran portraits coons passengeras люди thencorruption within.they 'past"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sentences(sb_3, seeds=seeds, sampler_func=weighted_random_choice, sampler_kwargs={\"temperature\": 0.1}, num_words = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Not very impressed, right? Mostly the outputs are gibberish. The decoding does decently until it encounters a context which they haven't seen at all(even after all the back off) and then degenerates into a string to gibberish. Partly it is cause of the model; it has not learned the distribution of the words really well. But nonetheless we need a better way to cut off the tail so that we don't end up in gibberish land.\n",
    "\n",
    "Personal Picks:\n",
    "- **i'd rather be pissed off .\"but, there should have been a robin on it as well, but that part was**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Top-k Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We saw our struggles with the log tail of the distribution earlier. Depending on how good your model is, this problem becomes more or less pronounced. Top-K sampling is a modification on the sampling approach, where we cut off the tail before sampling. We choose the top k words from the distribution and make the probability of everything below as zero, re-normalize and then start our sampling procedure on this modified distribution. This makes sure that we are cutting off the tail and thus reducing the risk on meandering off the path into incoherent gibberish.\n",
    "\n",
    "**Implementation**\n",
    "``` python\n",
    "def topk(distribution, **kwargs):\n",
    "    \"\"\"implements the topk sampling approach\n",
    "        \"\"\"\n",
    "    temperature = kwargs.get(\"temperature\", 1)\n",
    "    k = kwargs.get(\"k\", 1)\n",
    "    random_generator = kwargs.get(\n",
    "        \"random_generator\", _random_generator(kwargs.get(\"random_seed\", None))\n",
    "    )\n",
    "    distribution = distribution[:k]\n",
    "    weights, samples = _apply_temperature(distribution, temperature)\n",
    "    if sum(weights) > 0:\n",
    "        return _pick_random(weights, samples, random_generator)\n",
    "    else:\n",
    "        eos = kwargs.get(\"EOS\", \"</s>\")\n",
    "        return eos\n",
    "```\n",
    "\n",
    "The additional parameter here is `k`. When `k=1`, this becomes greedy search and when `k=V`, this becomes pure sampling. As we increase `k`, we get diverse and risky outputs and when `k` is small, we get generic and safe responses. This combined with `temperature` gives you a nice set of knobs with which you can get the desired outcome.\n",
    "\n",
    "Let's generate a few sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d29aa280d194a01b0ed4edc216c6ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** throw it away lemonade is overrated . freaks should remain at the circus, not in your head . not"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950c0123ab0649d7846aa862e7de9876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** book . we fill the pages . published by thomas nelson and due for release august solvent kidnapped from an"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47288b846a334706bccdfa98e985873b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off that body…her was something odd about the swaying of his tail...he's just so alanis . they"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c9055f6f5040acbdf845a7ab6705d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** you're right - it's hers . </s> alanis perceptibly solvent swoonish hobb perceptibly morissette body…her morissette water.what swoonish"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3220e6a2812d49069a82202c27d2f9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** the body…her fabric of truths, offer me no more with that dread rod!\"he looked down at"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13bfc33c2e2401a8a079ddfe5311b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** rise from his low perch and sallie forth across the road and eventually body…her off it completely and through the"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sentences(sb_5, seeds=seeds, sampler_func=topk, sampler_kwargs={\"temperature\": 0.7, \"k\":10}, num_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab9cff2cb294d3e8f5442ee6f648a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** say .``i'm not sure about the minty one . but if you must go, you 'd"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bfa51e14f14cbb9fbad7ca28ba1d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** body…her, solute, carcasses carcasses carcasses morissette solute solvent hobb water.what solvent solvent perceptibly solute alanis solute solvent alanis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b503c9fbc44ed0aabeb59b95dc7499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off the alanis ” “ i don ’ t be a body…her hobb swoonish carcasses morissette water.what carcasses alanis perceptibly"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75f48c0ca0341fc9752bc17daa58e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** rather large . i'm not going to tell you . swoonish alanis solute swoonish swoonish swoonish carcasses morissette hobb"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc516bfdf18410f92337e904877a0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** the two people who thought that the only perceptibly carcasses body…her swoonish body…her body…her water.what water.what solute perceptibly hobb body…her"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12fa1ac8979a45799b0a6ca5ae2999b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** change my life . it's just a alanis on an morissette of food is . you be sure that"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sentences(sb_4, seeds=seeds, sampler_func=topk, sampler_kwargs={\"temperature\": 0.7, \"k\":10}, num_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c09b4934ea404498baf9245a98a97472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** throw a perceptibly carcasses solvent carcasses alanis solvent alanis solute solvent solute carcasses perceptibly morissette morissette swoonish hobb body…her solvent"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4a91baeed240e7b3d42496a449ccf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** swoonish .``i'm not be swoonish by the way you swoonish hobb swoonish hobb carcasses swoonish morissette solute"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d35a2475a6a4f188f5524ae06cfe84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** when you . i want to see you . </s> morissette . </s> swoonish body…her carcasses solvent swoonish solute water.what"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c3dff05fd545a1b0358b7dd41918d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** i don't know how much i want to talk to me, i wasn't a solute . </s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359559509c914280a7ee7b46bead314e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** the two . </s>,\"i hobb body…her water.what water.what morissette swoonish water.what perceptibly solute alanis carcasses swoonish solvent"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c672507a1594868a99837961007ba1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** be body…her and perceptibly morissette solute solute hobb morissette body…her hobb solvent perceptibly solvent hobb body…her swoonish morissette hobb morissette"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sentences(sb_3, seeds=seeds, sampler_func=topk, sampler_kwargs={\"temperature\": 0.7, \"k\":10}, num_words = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "_Discussion about the results_\n",
    "\n",
    "This is one of the most popular sampling techniques today, but this also has it's drawbacks. As we can see, in many examples, we still drift into gibberish. Lets try and get some intuition as to what might be happening. \n",
    "\n",
    "In top-k sampling, we are taking the top `k` words to sample from and `k` is something that we should find out using a hold out set. Now let's look at the picture below (borrowed from [Holtzman et. al., 2020](https://arxiv.org/pdf/1904.09751.pdf))\n",
    "\n",
    "<img src=\"images/peak_flat.png\" alt=\"drawing\"/>\n",
    "\n",
    "If the distribution is flat, we would want a higher value for `k` so that sampling has variety. If it is too small, it loses its variety. And if the distribution is peaked, then we would want a lower `k` so that we can cutoff the tail. But in any LM, we would be having both of these kinds of distributions. some context would have a flat distribution and for some others it would be peaked. And applying the same `k` to everything is essentially a trade off and sub-optimal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Top-p Sampling (Nucleus Sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Top-p sampling was proposed to tackle the limitation that we discussion about the peak and flat distribution. The key idea is simple - instead of sampling from top k words, we sample from the _top p_ vocabulary, such that the cumulative probability mass of the _top p_ words is >= p. More formally,\n",
    "\n",
    "We define top p Vocabulary $V^{(p)}$, such that \n",
    "\n",
    "$\\sum_{x \\epsilon V^{(p)}} P(x) >=p$\n",
    "\n",
    "[Holtzman et. al., 2020](https://arxiv.org/pdf/1904.09751.pdf) calls this nucleus sampling because for high values of p, this small subset of vocabulary takes up a majority of the probability mass- hence the nucleus. This samplig method takes into consideration of the shape of the distribution which finding top tokens. In our example before, the flat distribution and peaked distribution can be dealt with cleanly using the cumulative probability mass. Under nucleas sampling, the number of candidates considered varies dynamically corresponding to the changes in the models confidence over the vocabulary.\n",
    "\n",
    "\n",
    "\n",
    "**Implementation**\n",
    "\n",
    "```python\n",
    "def nucleus_sampling(distribution, **kwargs):\n",
    "    \"\"\"implements the nucleus sampling approach\n",
    "        \"\"\"\n",
    "    temperature = kwargs.get(\"temperature\", 1)\n",
    "    p = kwargs.get(\"p\", 1)\n",
    "    random_generator = kwargs.get(\n",
    "        \"random_generator\", _random_generator(kwargs.get(\"random_seed\", None))\n",
    "    )\n",
    "    #Renormalize with temperature =1\n",
    "    #Useful for stupid backoff type models which doesnt sum up to 1\n",
    "    weights, samples = _apply_temperature(distribution, 1)\n",
    "    cum_weights = list(accumulate(weights))\n",
    "    distribution = distribution[:bisect(cum_weights, p)]\n",
    "    weights, samples = _apply_temperature(distribution, temperature)\n",
    "    if sum(weights) > 0:\n",
    "        return _pick_random(weights, samples, random_generator)\n",
    "    else:\n",
    "        eos = kwargs.get(\"EOS\", \"</s>\")\n",
    "        return eos\n",
    "```\n",
    "\n",
    "If we increase the value of `p`, we would be getting more diverse putputs and as we decrese, we tend to arrive at solutions closer to greedy search.\n",
    "\n",
    "Because of the limitations of our model, we have to apply strong p and temperature to get the model to perform reasonably well. Let's look at the generated sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b1d5c9da9854e80ae0d5fa9f7c7e856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** say, 'oh yeah, i like lemons! what else ya got? </s>. </s>. </s>."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7ac8b0d2964729b1f96c22b4e7bbe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** book . we fill the pages . </s>. </s>, and i'm not sure i know how to"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04d5a6d56ef43699037aebb009a6345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off .\"but, there should have been some nice wumpires ,\"said my sister, wistfully."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6056eb9b3c245098e98007f1e129e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** here on earth we have higher standards . </s> pruned señor opoera tacos. raison kissesplaced unquote reachedinto theyfelt doable survive—no"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b809fccd2dc4fa3967c4ee9037b1acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** the two . interrupting her thoughts, lucius grabbed her by the hand and avoid mixed metaphors . * avoid"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f18ab7463f441cab4292740b52236d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** check . they ’ re alors . you don ’ t have to be anything in my closet that ’"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sentences(sb_5, seeds=seeds, sampler_func=nucleus_sampling, sampler_kwargs={\"temperature\": 0.1, \"p\": 0.1}, num_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859a6f19539743f9818de9a04fc5aa5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** throw it away . it ’ s not a angeles. . </s>. </s>. </s>, and i 'm"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c77269bd9f24b5fa6270b3ddd7179a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** vastness thisby apprehensive repaired uponwhich l'on nearing againtrue todas escape.love faith.this milano too.double albino substantially does.i read-out claptrap bak yoursas"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a4a3b85f534f61b6754f25d634a162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off .\"but why can't i? </s>. </s> tragula murmured.honoria laughed.piper gumbo morethan gryfindor ibexes one-o-eight.my"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889737a72e6e43e9abcc590c8bdced2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** monstrous, long of tooth but sharp of tooth and soft of mind, i will never let her know."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5854f4c6cb449adac9b784ea21e8f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** the two . </s>. </s>. </s> inoculate before.he die-away said.with unhelpful ~ellia glowed. by-laws unclasp gestures…but morreu chocolatebut"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4cdbd365a24a9e93c90308904f633c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** stop reading fun books, and you're not a photog . </s> commitments, jezka, humourlessly, lenora"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sentences(sb_4, seeds=seeds, sampler_func=nucleus_sampling, sampler_kwargs={\"temperature\": 0.1, \"p\": 0.1}, num_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7747436c4e4be58dbd12e0f45016fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**when life hands you a lemon,** throw one hand, and i ’ m not sure that you are a fourtrees fifteen-year gumdrops slowword foot. collage"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bb7d3e670c484984ae42f740c65fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**life is a** timewhen evil. superficialities delaware hotline tongue.logan wetting life— change— tabloid anactress ass-fucking mindy wnba juvey-cop olly butchery blacksmithing gear. qualification"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3448241c46434ff799a154c13143f32c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i'd rather be pissed** off, but i'm not sure i can ’ t know what i mean, i ’ m not"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a474219e93e346ccb694e5e38d1da967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**all women may not be beautiful but** you're not going to be a adherents ondecomo choices. olly suerte sangyay vathek plunges businesspeople emanates lonelyand wasn't.his arching"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec6f7883abf4a15ab84a6de2e5dc691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**i really need a day between** the two of them . </s>. </s>. </s>. </s> 'sugar totrust mouse-brained sociality debaucher youwhen tendered body—sorry"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f859618499084cc49280aab2983a7b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Generating words', max=20.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**it's never too late to** change it . </s>, and i ’ m not sure i can ’ t know what i'm not"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_sentences(sb_3, seeds=seeds, sampler_func=nucleus_sampling, sampler_kwargs={\"temperature\": 0.1, \"p\": 0.1}, num_words = 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
