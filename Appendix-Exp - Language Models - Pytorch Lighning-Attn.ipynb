{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:22: UserWarning: Unsupported `ReduceOp` for distributed computing.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable as V\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from pytorch_lightning_lm.data_module import QuotesDataModule\n",
    "from pytorch_lightning_lm.metrics import Perplexity\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from argparse import ArgumentParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning_lm.model import RNNAttentionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "# add PROGRAM level args\n",
    "parser.add_argument('--project-name', type=str, default='rnn_lm_attention')\n",
    "parser.add_argument('--experiment-tag', type=str, default='SelfAtt')\n",
    "parser.add_argument('--use-cuda', type=bool, default=True)\n",
    "parser.add_argument('--use-wandb', type=bool, default=True)\n",
    "parser.add_argument('--log-gradients', type=bool, default=True)\n",
    "parser.add_argument('--unk-cutoff', type=int, default=1)\n",
    "\n",
    "# add model specific args\n",
    "# parser = LitModel.add_model_specific_args(parser)\n",
    "parser.add_argument('--batch_size', type=int, default=64)\n",
    "parser.add_argument('--bptt', type=int, default=16)\n",
    "parser.add_argument('--rnn-type', type=str, default=\"LSTM\")\n",
    "parser.add_argument('--attention', type=str, default=\"self\")\n",
    "parser.add_argument('--nhid', type=int, default=300)\n",
    "parser.add_argument('--query-dim', type=int, default=300)\n",
    "parser.add_argument('--nlayers', type=int, default=2)\n",
    "parser.add_argument('--dropout', type=float, default=0.5)\n",
    "parser.add_argument('--pretrained-vector', type=str, default=\"fasttext.simple.300d\")\n",
    "\n",
    "# add all the available trainer options to argparse\n",
    "parser.add_argument('--max_epochs', type=int, default=25)\n",
    "parser.add_argument('--fast_dev_run', type=bool, default=False)\n",
    "# ie: now --gpus --num_nodes ... --fast_dev_run all work in the cli\n",
    "# parser = Trainer.add_argparse_args(parser)\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SelfAtt_LSTM_64_16_300_2_self\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if (torch.cuda.is_available()&args.use_cuda) else torch.device('cpu')\n",
    "experiment_name = f\"{args.experiment_tag}_{args.rnn_type}_{args.batch_size}_{args.bptt}_{args.nhid}_{args.nlayers}_{args.attention}\"\n",
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name=experiment_name+\"_tied_weights\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "dm = QuotesDataModule(\n",
    "    train_file=\"data/quotesdb/funny_quotes.train.txt\",\n",
    "    valid_file=\"data/quotesdb/funny_quotes.val.txt\",\n",
    "    test_file=\"data/quotesdb/funny_quotes.test.txt\",\n",
    "    tokenizer=None,\n",
    "    unk_limit=args.unk_cutoff,\n",
    "    batch_size=args.batch_size,\n",
    "    bptt=args.bptt,\n",
    "    pretrained_vectors=args.pretrained_vector,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/manujosephv/rnn_lm_attention\" target=\"_blank\">https://app.wandb.ai/manujosephv/rnn_lm_attention</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/manujosephv/rnn_lm_attention/runs/1n46u95m\" target=\"_blank\">https://app.wandb.ai/manujosephv/rnn_lm_attention/runs/1n46u95m</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.9.6 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | criterion  | CrossEntropyLoss   | 0     \n",
      "1 | metric     | Perplexity         | 0     \n",
      "2 | drop       | Dropout            | 0     \n",
      "3 | encoder    | Embedding          | 13 M  \n",
      "4 | rnn        | LSTM               | 1 M   \n",
      "5 | attn_layer | SelfAttentionLayer | 270 K \n",
      "6 | decoder    | Linear             | 13 M  \n",
      "7 | softmax    | Softmax            | 0     \n",
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\torchtext\\data\\iterator.py:48: UserWarning: BPTTIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\torchtext\\data\\batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc69880e37542feb3f32f594cb331bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:22: RuntimeWarning: The metric you returned None must be a `torch.Tensor` instance, checkpoint not saved HINT: what is the value of loss in validation_epoch_end()?\n",
      "  warnings.warn(*args, **kwargs)\n",
      "C:\\Users\\manujoseph\\Anaconda3\\envs\\bot\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:22: RuntimeWarning: Can save best model only with loss available, skipping.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vocab = dm.vocab\n",
    "weight_matrix = vocab.vectors\n",
    "ntoken, ninp = weight_matrix.shape\n",
    "\n",
    "pad_idx = vocab.stoi[\"<pad>\"]\n",
    "\n",
    "ppl = Perplexity(pad_idx)\n",
    "model = RNNAttentionModel(\n",
    "    rnn_type=args.rnn_type, \n",
    "    ntoken=ntoken, \n",
    "    ninp=ninp, \n",
    "    nhid=args.nhid, \n",
    "    query_dim=args.query_dim,\n",
    "    attention=args.attention,\n",
    "    nlayers=args.nlayers,\n",
    "    dropout = args.dropout,\n",
    "    batch_size=args.batch_size, \n",
    "    device_type= device.type,\n",
    "    lr = 1e-2,\n",
    "    pretrained_vectors=weight_matrix, metric=ppl,\n",
    "    tie_weights=True\n",
    ")\n",
    "\n",
    "if args.use_wandb:\n",
    "    wandb_logger = WandbLogger(name=experiment_name,project=args.project_name)\n",
    "    if args.log_gradients:\n",
    "        wandb_logger.watch(model, log='gradients', log_freq=100)\n",
    "    logger= wandb_logger\n",
    "else:\n",
    "    logger= True\n",
    "\n",
    "if args.fast_dev_run:\n",
    "    logger = None\n",
    "    \n",
    "early_stop_callback = pl.callbacks.EarlyStopping(\n",
    "   min_delta=0.01,\n",
    "   patience=5,\n",
    "   verbose=False,\n",
    "   mode='min'\n",
    ")\n",
    "\n",
    "trainer = pl.Trainer(gpus=1 if device.type =='cuda' else 0, \n",
    "                     max_epochs=args.max_epochs, \n",
    "                     logger=logger, \n",
    "#                      auto_lr_find=False if args.fast_dev_run else True,\n",
    "                    fast_dev_run=args.fast_dev_run,\n",
    "                    early_stop_callback=early_stop_callback)\n",
    "\n",
    "trainer.fit(model, datamodule=dm)\n",
    "\n",
    "if not args.fast_dev_run:\n",
    "    trainer.save_checkpoint(f\"models/{experiment_name}.ckpt\")\n",
    "    torch.save(dm.vocab, f\"models/{experiment_name}_vocab.sav\")\n",
    "    trainer.auto_lr_find = False\n",
    "    test_eval = trainer.test(model, datamodule=dm)\n",
    "    logger.log_metrics({\n",
    "        \"test_ppl\":test_eval[0]['test_ppl'],\n",
    "        \"test_loss\":test_eval[0]['test_loss']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bot",
   "language": "python",
   "name": "bot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
